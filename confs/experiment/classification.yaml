# @package _global_

experiment_name: ${db_name}_${seed}_classification # DO NOT CHANGE
experiment_subname: ${model_name}_${preprocessing.imputer.method}_${preprocessing.numerical.method}_${preprocessing.categorical.method} # DO NOT CHANGE
pipeline: simple # DO NOT REMOVE

seed: 42 # Seed for randomness control
verbose: 1 # 0 or 1, verbosity of the training

continue_experiment: True # True or False, if the experiment should be continued from where it was interrupted

naim_version: cat
num_layers: 6

db_name: ${db.name}
model_name: ${model.name}

defaults: # DO NOT CHANGE
  - _self_ # DO NOT CHANGE
  - paths@: default # DO NOT CHANGE
  - paths: experiment_paths # DO NOT CHANGE

  - databases@db: adult # Name of the configuration file of the dataset

  - cross_validation@test_cv: stratifiedkfold  # Cross-validation strategy for the test set
  - cross_validation@val_cv: holdout           # Cross-validation strategy for the validation set

  - preprocessing/numerical: normalize # normalize or standardize
  - preprocessing/categorical: categoricalencode # categoricalencode or onehotencode
  - preprocessing/imputer: noimputation # simple or knn or iterative or noimputation

  - model_type_params@dl_params: dl_params # DO NOT CHANGE
  - model_type_params@ml_params: ml_params # DO NOT CHANGE

  - model: naim # Name of the model to use

  - model_type_params@train.dl_params: dl_params # DO NOT CHANGE

  - initializer@train.initializer: xavier_uniform # DO NOT CHANGE
  - loss@train.loss.CE: cross_entropy             # DO NOT CHANGE
  - regularizer@train.regularizer.l1: l1          # DO NOT CHANGE
  - regularizer@train.regularizer.l2: l2          # DO NOT CHANGE
  - optimizer@train.optimizer: adam               # DO NOT CHANGE
  - train_utils@train.manager: train_manager      # DO NOT CHANGE

  - metric@train.set_metrics.auc: auc
  - metric@train.set_metrics.f1: f1_score # Metric to use for the early stopping

  - metric@performance_metrics.auc: auc # Metric to use for the performance evaluation
  - metric@performance_metrics.accuracy: accuracy # Metric to use for the performance evaluation
  - metric@performance_metrics.recall: recall # Metric to use for the performance evaluation
  - metric@performance_metrics.precision: precision # Metric to use for the performance evaluation
  - metric@performance_metrics.f1_score: f1_score # Metric to use for the performance evaluation
  - metric@performance_metrics.mcc: mcc # Metric to use for the performance evaluation
  - metric@performance_metrics.gmean: gmean # Metric to use for the performance evaluation
