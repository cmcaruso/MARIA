name: TabNet
framework: torch
model_type: tabular

model_tasks:
  - classification

label_types:
  - binary
  - categorical

set_params_function:
  _target_: CMC_utils.models.set_tabnet_torch_params

init_params:
  _target_: CMC_utils.models.TabNetTorch
  _convert_: all

  input_dim:

  output_dim:

  n_d: 8
  # Width of the decision prediction layer. Bigger values gives more capacity to the model with the risk of overfitting. Values typically range from 8 to 64.
  # int (default=8)

  n_a: 8
  # Width of the attention embedding for each mask. According to the paper n_d=n_a is usually a good choice. (default=8)
  # int (default=8)

  n_steps: 3
  # Number of steps in the architecture (usually between 3 and 10)
  # int (default=3)

  gamma: 1.3
  # This is the coefficient for feature reusage in the masks. A value close to 1 will make mask selection least correlated between layers. Values range from 1.0 to 2.0.
  # float (default=1.3)

  cat_idxs: []
  # List of categorical features indices.
  # list of int (default=[] - Mandatory for embeddings)

  cat_dims: []
  # List of categorical features number of modalities (number of unique values for a categorical feature) /!\ no new modalities can be predicted
  # list of int (default=[] - Mandatory for embeddings)

  cat_emb_dim: 1
  # List of embeddings size for each categorical features. (default =1)
  # list of int (optional)

  n_independent: 2
  # Number of independent Gated Linear Units layers at each step. Usual values range from 1 to 5.
  # int (default=2)

  n_shared: 2
  # Number of shared Gated Linear Units at each step Usual values range from 1 to 5
  # int (default=2)

  epsilon: 1e-15
  # Should be left untouched.
  # float (default 1e-15)

  virtual_batch_size: 128
  # Size of the mini batches used for “Ghost Batch Normalization”. /!\ virtual_batch_size should divide batch_size
  # int (default=128)

  momentum: 0.02
  # Momentum for batch normalization, typically ranges from 0.01 to 0.4 (default=0.02)
  # float, default=0.02

  mask_type: sparsemax
  # str (default=’sparsemax’) Either “sparsemax” or “entmax”: this is the masking function to use for selecting features.

#############################################
fit_params: {}

train_function:
  _target_: CMC_utils.models.train_torch_model

test_function:
  _target_: CMC_utils.models.test_torch_model

save_function:
  _target_: CMC_utils.save_load.save_model

file_extension: pth

load_function:
  _target_: CMC_utils.save_load.load_model